# genetic-reinforcement-learning-unity
Problem Statement:<br/>
Using AI concepts to solve the underlying problem of learning form the blunder judgements made during a problem solving. We have devised a program that showcases self-learning car that traverse through a track that avoids obstacles. A main difficulty for applying reinforcement learning methods in practice is the large action space problem. In this, by means of the concept of genetic optimization, we have proposed a reinforcement learning algorithm. Our genetic algorithm for reinforcement learning has solved the action space problem quite well.<br/><br/>
Idea:<br/>
It’s an offspring of simple neural network, with combination of Genetic Algorithm and Reinforcement learning. Cars are trained over in real time and with each generation the cars will evolve to traverse the track. <br/><br/>
Description:<br/>
At the start of each generation 20 cars are generated. Each car has its own neural network, which makes up the ‘intelligence’ of the car. The cars also have 5 front facing sensors, which measure the distance to obstacles and serve as the input of the neural network. If a car hits an obstacle, it dies.<br/>
Once all cars have died, a new generation is formed using an evolutionary algorithm. The ‘genes’ of the two cars with the best fitness are crossed and 20 new ‘children’ are born. Additionally, these children get slightly mutated. Finally, these new-born child ren try to manoeuvre through the course. The fitness of a car is calculated by its progress throughout the course. A car's ‘genes’ are the weights of its neural network. The neural networks are simple feed-forward networks and consist of 5 input nodes, 2 output nodes and 2 hidden layers with 4 and 3 nodes.<br/><br/>
The Simulation:<br/>
Cars have to navigate through a course without touching the walls or any other obstacles of the course. A car has five front-facing sensors which measure the distance to obstacles in a given direction. The readings of these sensors serve as the input of the car's neural network. Each sensor points into a different direction, covering a front facing range of approximately 90 degrees. The maximum range of a sensor is 10 unity units. The output of the Neural Network then determines the car’s current engine and turning force.<br/><br/>
 

The Neural Network:<br/>
The Neural Network used is a standard, fully connected, feedforward Neural Network. It comprises 4 layers: an input layer with 5 neurons, two hidden layers with 4 and 3 neurons respectively and an output layer with 2 neurons.<br/><br/>
Training the Neural Network:<br/>
The weights of the Neural Network are trained using an Evolutionary Algorithm known as the Genetic Algorithm.<br/>
At first there are N randomly initialised cars spawned. The best cars are then selected to be recombined with each other, creating new "offspring" cars. These offspring cars then form a new population of N cars and are also slightly mutated in order to inject some more diversity into the population. The newly created population of cars then tries to navigate the course again and the process of evaluation, selection, recombination and mutation starts again. One complete cycle from the evaluation of one population to the evaluation of the next is called a generation.<br/><br/>
User Interface:<br/>
The user interface always displays the data of the current best car. In the top left corner, the Neural Network's output (engine and turning) is displayed. Right below the output, the evaluation value is displayed (the evaluation value is equal to the percentage of course completion). In the lower left corner, a generation counter is displayed. In the upper right corner, the Neural Network of the current best car is displayed. The weights are symbolised by the colour and width of the connections between neurons: The wider a connection, the bigger the absolute value of the weight; Green means that the weight is positive, red means that the weight is negative.<br/><br/>
